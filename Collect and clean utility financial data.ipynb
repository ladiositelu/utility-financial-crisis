{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Clean data\n",
    "\n",
    "I collect data from \n",
    "1. COMPUSTAT\n",
    "2. U.S Energy Information Administration (EIA)\n",
    "3. Regulatory Researc Associates (RRA)\n",
    "\n",
    "I clean the data, merge and preprocess it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets\n",
    "There are three data different datasets that I use. \n",
    "1. df contains data on fundamentals (balance sheet etc)\n",
    "2. dff contains utility specific information \n",
    "3. dfff contains utility credit ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('.../data/utility_fundamentals_Qnew.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dff=pd.read_csv('.../data/utility_specific_compustat_quarterly_final.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfff=pd.read_csv('.../data/utility_creditratings.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Dataset has\", str(df.shape[0]) + \" rows and\",str(df.shape[1]) + \" columns\"\n",
    "print \"Dataset has\", str(dff.shape[0]) + \" rows and\",str(dff.shape[1]) + \" columns\"\n",
    "print \"Dataset has\", str(dfff.shape[0]) + \" rows and\",str(dff.shape[1]) + \" columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"There are\", str(len(df.tic.unique())) + \" companies in the fundamental dataset\"\n",
    "print \"There are\", str(len(dff.tic.unique())) + \" companies in the utility specific dataset\"\n",
    "print \"There are\", str(len(dfff.tic.unique())) + \" companies in the utility credit ratings dataset\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are companies Incorporated?\n",
    "I am only interested in US companies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(df.fic.unique()) #fic is the foreign incorporation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The number of firms incorporated outside the USA:\", len(df[df.fic != 'USA']['conm'].unique())\n",
    "df=df[df.fic=='USA'] # select only US firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"There are\", str(len(df.tic.unique())) + \" companies REMAINING in the fundamental dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firm ownership structure\n",
    "I'm interested in publicly traded firms and their subsidiaries which implies firms that have 0 and 1 as the stko variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(df.stko.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(df[df.stko>1]['conm'].unique()) #number of companies not publicly traded or subsidiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select public traded and subsidiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[(df.stko==0) | (df.stko==1)] #0 is for public traded and 1 is for their subsidiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"There are\", str(len(df[df.stko==1]['tic'].unique())) + \" subsidaries in the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[df.fyearq>2001] #remove 2001 from the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The number of public traded firms/subsidiaries incorporated in the USA:\", len(df['conm'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for columns that have no values (empty) and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def column_check(data):\n",
    "    useless=[]\n",
    "    useful=[] # hold columns that are not entirely null\n",
    "    for row in list(data.columns):\n",
    "        try:#if the # empty rows==total # of rows, this means all rows are empty\n",
    "            if pd.isnull(data[row]).value_counts()[1]==data.shape[0]:\n",
    "                useless.append(row)\n",
    "            else:\n",
    "                useful.append(row)\n",
    "        except KeyError:\n",
    "            useful.append(row)\n",
    "    return useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[column_check(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape #93 columns were completely missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date']=pd.to_datetime(df['datadate'])\n",
    "dff['date']=pd.to_datetime(dff.date)\n",
    "dfff['date']=pd.to_datetime(dfff.datadate)\n",
    "df['year']=df['date'].dt.year #create a year variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match=list(set(dff.columns) & set(df.columns)) # create the common list of variables to match the data with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['tic','date'])\n",
    "dff=dff.sort_values(['tic','date'])\n",
    "dfff=dfff.sort_values(['tic','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,dff,on=match,how='left')\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_match=list(set(df.columns)& set(dfff.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,dfff,on=new_match, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with capx and other variables\n",
    "Some variables are given as year to date. To get the actual quarterly equivalent, one must substract from the lagged value\n",
    "Steps\n",
    "1. First group the data by ticker(company) and year\n",
    "2. Subtract lagged value from actual value(year to date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped=df.groupby(['tic','fyearq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new=[] ## for every tic and fiscal year, \n",
    "for group in grouped.groups.keys():\n",
    "    DF=grouped.get_group(group)\n",
    "    DF['capx']=DF['capxy']-DF['capxy'].shift(1)\n",
    "    DF['plant_gross_add']=DF['uptacy']-DF['uptacy'].shift(1) #Utility Plant - Gross Additions\n",
    "    DF['stock_sale']=DF['sstky']-DF['sstky'].shift(1)\n",
    "    DF['stock_purchase']=DF['prstkcy']-DF['prstkcy'].shift(1)\n",
    "    DF['cash_dividends']=DF['dvy']-DF['dvy'].shift(1)\n",
    "    DF['LT_debt_issuance']=DF['dltisy']-DF['dltisy'].shift(1)\n",
    "    DF['LT_debt_reduction']=DF['dltry']-DF['dltry'].shift(1)\n",
    "    DF['NOCF']=DF['oancfy']-DF['oancfy'].shift(1)\n",
    "    DF['NFCF']=DF['fincfy']-DF['fincfy'].shift(1)\n",
    "    DF['NICF']=DF['ivncfy']-DF['ivncfy'].shift(1)\n",
    "    DF['property_sale']=DF['sppey']-DF['sppey'].shift(1)\n",
    "    DF['investment_sale']=DF['sivy']-DF['sivy'].shift(1)\n",
    "    DF['other_cash']=DF['uoisy']-DF['uoisy'].shift(1)\n",
    "    DF['asset_growth']=DF['atq']-DF['atq'].shift(1)\n",
    "    DF['yearly_total_sales']=DF['saleq'].sum()\n",
    "    DF['yearly_total_assets']=DF['atq'].sum()\n",
    "    new.append(DF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df=pd.concat(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df=new_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def if_first_null(data,x,y):\n",
    "    dd=[]\n",
    "    ### check if first value is null, if so replace it with the year to date\n",
    "    for i in range(len(data)):\n",
    "        if pd.isnull(data[x])[i]==True:\n",
    "            dd.append(data[y][i])\n",
    "        else:\n",
    "            dd.append(data[x][i])\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['capx']=if_first_null(new_df,'capx','capxy')\n",
    "new_df['plant_gross_add']=if_first_null(new_df,'plant_gross_add','uptacy')\n",
    "new_df['stock_sale']=if_first_null(new_df,'stock_sale','sstky')\n",
    "new_df['stock_purchase']=if_first_null(new_df,'stock_purchase','prstkcy')\n",
    "new_df['LT_debt_issuance']=if_first_null(new_df,'LT_debt_issuance','dltisy')\n",
    "new_df['LT_debt_reduction']=if_first_null(new_df,'LT_debt_reduction','dltry')\n",
    "new_df['other_cash']=if_first_null(new_df,'other_cash','uoisy')\n",
    "new_df['property_sale']=if_first_null(new_df,'property_sale','sppey')\n",
    "new_df['investment_sale']=if_first_null(new_df,'investment_sale','sivy')\n",
    "new_df['cash_dividends']=if_first_null(new_df,'cash_dividends','dvy')\n",
    "new_df['NOCF']=if_first_null(new_df,'NOCF','oancfy')\n",
    "new_df['NFCF']=if_first_null(new_df,'NFCF','fincfy')\n",
    "new_df['NICF']=if_first_null(new_df,'NICF','ivncfy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"The number of unique companies in the dataset: \", len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States and regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'There are', str(len(df.state.unique())) + ' states in the sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states=list(np.sort(df.state.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regulation data from U.S Energy Information Administration\n",
    "deregulation and retail_choice values were obtained based on the sorted list of states and matching with relevant data from EIA on deregulation and retail_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deregulation=['NO','suspended','suspended','suspended','NO','YES','YES','YES','NO','NO','NO','NO','NO','YES','NO','NO','NO','NO','YES','YES','YES','YES','NO','NO','NO','suspended','NO','YES','YES','suspended','suspended','YES','YES','NO','YES','YES','NO','NO','YES','suspended','NO','NO','NO','NO']\n",
    "retail_choice=['NO','NO','NO','suspended','NO','YES','YES','YES','NO','NO','NO','NO','NO','YES','NO','NO','NO','NO','YES','YES','YES','YES','NO','NO','NO','NO','NO','YES','YES','NO','NO','YES','YES','NO','YES','YES','NO','NO','YES','suspended','NO','NO','NO','NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S=pd.DataFrame(states)\n",
    "S.rename(columns={0:'state'},inplace=True) #change column 0 to state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S['deregulation']=deregulation\n",
    "S['retail_choice']=retail_choice\n",
    "S['deregulation']=S['deregulation'].str.upper()\n",
    "S['retail_choice']=S['retail_choice'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S.deregulation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,S,left_on='state',right_on='state',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adjust states that were deregulated then moved to suspend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['date']<datetime.datetime(2007,2,1) and row['state']=='VA':\n",
    "        dd.append('YES')\n",
    "    elif row['date'] < datetime.datetime(2004,10,1) and row['state']=='AZ':\n",
    "        dd.append('YES')\n",
    "    else:\n",
    "        dd.append(row['deregulation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['deregulation']=dd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset value variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['log_asset']=np.log(df['atq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['market_value']=df['prccq'] * df['cshoq'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['capx_asset']=(df['capx']/df['atq']) *100 # capital expenditure to asset\n",
    "df['log_capx']=np.log(df.capx)\n",
    "df['log_capx_asset']=np.log(df.capx_asset)\n",
    "df['ppentq_asset']=(df['ppentq']/df['atq']) *100 \n",
    "df['ppegtq_asset']=(df['ppegtq']/df['atq']) *100\n",
    "df['RD_asset']=df.xrdq/df.atq # R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['plant_add_asset']=(df['plant_gross_add']/df['atq']) * 100\n",
    "df['log_plant_asset']=np.log(df.plant_add_asset)\n",
    "df['log_plant_add']=np.log(df.plant_gross_add)\n",
    "df['capital_intensity']=(df['ppegtq']/df.atq) * 100 #gross plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['inventory_asset']=(df['invtq']/df.atq) * 100\n",
    "df['net_workingcap_asset']=((df.actq-df.lctq-df.cheq)/df.atq) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['stock_sale_asset']=(df.stock_sale/df.atq) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['net_equity_issuance']=df['stock_sale']-df['stock_purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['net_equity_asset']=(df.net_equity_issuance/df.atq)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['EED']=df['net_equity_issuance']/df['capx'] #external equity dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ROE']=(df.uniamiq-df.dvpq)/df.ceqq ## return on equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ROA']=df.uniamiq/df['atq'] #net income before extraordinary items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['total_debt_q']=df['dlcq']+df['dlttq'] # Total_debt== short-term debt(COMPUSTAT: DLCQ)+ long-term debt (DLTTQ).\n",
    "df['debt_asset']=(df['total_debt_q']/df['atq']) * 100\n",
    "df['ST_debt_asset']=(df['dlcq']/df.atq) * 100\n",
    "df['LT_debt_asset']=(df['dlttq']/df.atq) * 100\n",
    "df['leverage_ratio']=(df.total_debt_q/(df.seqq+df.dlttq))*100\n",
    "df['debt_equity']=df.total_debt_q/df.seqq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['LT_debt_issuance_asset']=(df.LT_debt_issuance/df.atq)*100\n",
    "df['LT_debt_reduction_asset']=(df.LT_debt_reduction/df.atq)*100\n",
    "df['net_debt']=df['LT_debt_issuance']-df['LT_debt_reduction']\n",
    "df['net_debt_asset']=(df['net_debt']/df['atq']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cash_asset']=(df['cheq']/df['atq']) * 100 #cash and short term investments/total assets\n",
    "df['other_cash_asset']=(df['other_cash']/df.atq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cash_dividends_asset']=(df['cash_dividends']/df.atq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cash_flow']=df['ibq'] + df['dpq'] +df['ppentq'] #Income Before Extraordinary Items plus Depreciation and Amortization\n",
    "df['cash_flow_asset']=(df['cash_flow']/df['atq']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sale_asset']=(df.saleq/df.atq) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['external_finance']=((df.plant_gross_add-df.cash_flow)/df.plant_gross_add) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['investment_sale_asset']=(df['investment_sale']/df['atq']) * 100\n",
    "df['property_sale_asset']=(df['property_sale']/df['atq']) * 100\n",
    "df['NOCF_asset']=(df['NOCF']/df['atq']) * 100\n",
    "df['NICF_asset']=(df['NICF']/df['atq']) * 100\n",
    "df['NFCF_asset']=(df['NFCF']/df['atq']) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earnings, interest, profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ebitda']=df['revtq']-df['xoprq'] + df['dpq'] #EBITDA = Revenue (REVTQ) â€“ Operating expenses (XOPRQ) + depreciation and amortization (DPQ)\n",
    "df['ebitda_asset']=(df['ebitda']/df['atq'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['retainedearnings_asset']=(df['req']/df.atq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['interest_coverage_ratio']=df['ebitda']/df['xintq']\n",
    "df['interest_coverage_ratio_asset']=df['interest_coverage_ratio']/df['atq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['profit']=(df['piq']/df['atq']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['yearly_total_sales_asset']=df['yearly_total_sales']/df['yearly_total_assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['stock_purchase_asset']=(df.stock_purchase/df.atq)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['payout_asset']=df['cash_dividends_asset']+ df['stock_purchase_asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['tic','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create lagged variables\n",
    "grouped=df.groupby(['tic',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new=[] ## for every tic and fiscal year, \n",
    "for group in grouped.groups.keys():\n",
    "    DF=grouped.get_group(group)\n",
    "    DF['lag_capx']=DF['capx'].shift(1)\n",
    "    DF['lag_plant_gross_add']=DF['plant_gross_add'].shift(1) #Utility Plant - Gross Additions\n",
    "    #DF['lag_stock_sale']=DF['stock_sale'].shift(1)\n",
    "    #DF['lag_stock_purchase']=DF['stock_purchase'].shift(1)\n",
    "    DF['lag_asset_growth']=DF['asset_growth'].shift(1)\n",
    "    DF['lag_cash_flow_asset']=DF['cash_flow_asset'].shift(1)\n",
    "    DF['lag_cash_asset']=DF['cash_asset'].shift(1)\n",
    "    DF['lag_debt_asset']=DF['debt_asset'].shift(1)\n",
    "    DF['lag_LT_debt_asset']=DF['LT_debt_asset'].shift(1)\n",
    "    DF['lag_ST_debt_asset']=DF['ST_debt_asset'].shift(1)\n",
    "    DF['four_lags_LT_debt_asset']=DF['LT_debt_asset'].shift(4)\n",
    "    DF['four_lags_ST_debt_asset']=DF['ST_debt_asset'].shift(4)\n",
    "    DF['four_lags_cash_asset']=DF['cash_asset'].shift(4)\n",
    "    DF['four_lags_debt_asset']=DF['debt_asset'].shift(4)\n",
    "    DF['four_lags_cash_flow_asset']=DF['cash_flow_asset'].shift(4)\n",
    "    DF['lag_sale_asset']=DF['sale_asset'].shift(1)\n",
    "    DF['four_lags_sale_asset']=DF['sale_asset'].shift(4)\n",
    "    DF['lag_yearly_total_sales_asset']=DF['yearly_total_sales_asset'].shift(4)\n",
    "    DF['lag_yearly_total_assets']=DF['yearly_total_assets'].shift(4)\n",
    "    #DF['net_debt_issuance']=DF['total_debt_q']-DF['total_debt_q'].shift(1)\n",
    "    new.append(DF)\n",
    "df=pd.concat(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sale_growth']=((df['sale_asset']-df['four_lags_sale_asset'])/df.four_lags_sale_asset) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['yearly_sale_growth']=(df['yearly_total_sales_asset']-df['lag_yearly_total_sales_asset'])/df['lag_yearly_total_sales_asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.saleq<=0]['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.saleq>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quarter_dummies=pd.get_dummies(df.fqtr,prefix='quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,quarter_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_list=list(df[pd.isnull(df.plant_add_asset)]['tic'].unique()) # companies that have some missing data on capx\n",
    "print \"There are \" + str(len(remove_list)) + \" companies with missing values on investment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for row in df['tic']:\n",
    "    if row in remove_list:\n",
    "        dd.append(0)\n",
    "    else:\n",
    "        dd.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['remove']=dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['fyearq']==2006 and row['fqtr']==2:\n",
    "        dd.append(1)\n",
    "    else:\n",
    "        dd.append(0)\n",
    "df['year_before']=dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tercile_group=df.groupby('year_before')\n",
    "NEW=[] ## \n",
    "for group in tercile_group.groups.keys():\n",
    "    DFF=tercile_group.get_group(group)\n",
    "    DFF['debt_tercile']=pd.qcut(DFF.debt_asset,3,labels=[\"low_debt\",\"medium_debt\",\"high_debt\"])\n",
    "    DFF['cash_tercile']=pd.qcut(DFF.cash_asset,3,labels=[\"low_cash\",\"medium_cash\",\"high_cash\"])\n",
    "    DFF['asset_tercile']=pd.qcut(DFF.atq,3,labels=[\"low_asset\",\"medium_asset\",\"high_asset\"])\n",
    "    NEW.append(DFF)\n",
    "df=pd.concat(NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['year_before']==1:\n",
    "        dd.append(row['debt_tercile'])\n",
    "    else:\n",
    "        dd.append(None)\n",
    "df['debt_tercile']=dd\n",
    "\n",
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['year_before']==1:\n",
    "        dd.append(row['cash_tercile'])\n",
    "    else:\n",
    "        dd.append(None)\n",
    "df['cash_tercile']=dd\n",
    "\n",
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['year_before']==1:\n",
    "        dd.append(row['asset_tercile'])\n",
    "    else:\n",
    "        dd.append(None)\n",
    "df['asset_tercile']=dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_group=df.groupby('year_before')\n",
    "NEW=[] ## \n",
    "for group in median_group.groups.keys():\n",
    "    DFF=median_group.get_group(group)\n",
    "    DFF['debt_median']=pd.qcut(DFF.debt_asset,2,labels=[\"LD\",\"HD\"])\n",
    "    DFF['cash_median']=pd.qcut(DFF.cash_asset,2,labels=[\"LC\",\"HC\"])\n",
    "    DFF['asset_median']=pd.qcut(DFF.atq,2,labels=[\"LA\",\"HA\"])\n",
    "    NEW.append(DFF)\n",
    "df=pd.concat(NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def year_before_median(data,finVar):\n",
    "    '''This function takes every value of the particular finVar \n",
    "    other than year before and sets it to 0'''\n",
    "    dd=[]\n",
    "    for index,row in data.iterrows():\n",
    "        if row['year_before']==1:\n",
    "            dd.append(row[finVar])\n",
    "        else:\n",
    "            dd.append(None)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['debt_median']=year_before_median(df,'debt_median')\n",
    "df['cash_median']=year_before_median(df,'cash_median')\n",
    "df['asset_median']=year_before_median(df,'asset_median')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['tic','fyearq','fqtr'])\n",
    "df['debt_tercile']=df['debt_tercile'].fillna(method='ffill')\n",
    "df['cash_tercile']=df['cash_tercile'].fillna(method='ffill')\n",
    "df['asset_tercile']=df['asset_tercile'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['tic','fyearq','fqtr'])\n",
    "df['debt_median']=df['debt_median'].fillna(method='ffill')\n",
    "df['cash_median']=df['cash_median'].fillna(method='ffill')\n",
    "df['asset_median']=df['asset_median'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define variables like year_cash, year_debt etc\n",
    "df['year_cash']=[df.cash_asset if x==1 else None for x in df['year_before']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def variable_yearbefore(data,yearV,finV):\n",
    "    '''This function takes the value of a financial variable from the year before'''\n",
    "    dd=[]\n",
    "    for index,row in data.iterrows():\n",
    "        if row[yearV]==1:\n",
    "            dd.append(row[finV])\n",
    "        else:\n",
    "            dd.append(None)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['year_cash']=variable_yearbefore(df,'year_before','cash_asset')\n",
    "df['year_debt']=variable_yearbefore(df,'year_before','debt_asset')\n",
    "df['year_ST_debt']=variable_yearbefore(df,'year_before','LT_debt_asset')\n",
    "df['year_LT_debt']=variable_yearbefore(df,'year_before','ST_debt_asset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['tic','fyearq','fqtr'])\n",
    "df['year_cash']=df['year_cash'].fillna(method='ffill')\n",
    "df['year_debt']=df['year_debt'].fillna(method='ffill')\n",
    "df['year_LT_debt']=df['year_LT_debt'].fillna(method='ffill')\n",
    "df['year_ST_debt']=df['year_ST_debt'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for index,row in df.iterrows():\n",
    "    if row['fyearq']<=2006:\n",
    "        dd.append(0)\n",
    "    elif row['fyearq']==2007 and row['fqtr']<=2:\n",
    "        dd.append(0)\n",
    "    else:\n",
    "        dd.append(1)\n",
    "df['post']=dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry component\n",
    "Need to figure out what sector of the electric power industry a company operates in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for row in df['busdesc']:\n",
    "    if 'vertical' in row:\n",
    "        dd.append('vertical')\n",
    "    elif 'generat' in row and 'transmi' in row and 'distribu' in row:\n",
    "        dd.append('vertical')\n",
    "    elif 'generat' in row and 'deliv' in row:\n",
    "        dd.append('vertical')\n",
    "    elif 'generat' in row and 'suppl' in row:\n",
    "        dd.append('vertical')\n",
    "    elif 'generat' in row and 'transmi' not in row and 'distribu' not in row and 'deliv' not in row:\n",
    "        dd.append('generation')\n",
    "    elif 'generat' not in row and 'transmi' in row and 'distribu' not in row:\n",
    "        dd.append('transmission')\n",
    "    elif 'generat' not in row and 'transmi' not in row and 'distribu' in row:\n",
    "        dd.append('distribution')\n",
    "    else:\n",
    "        dd.append('T&D')\n",
    "df['utility_type']=dd\n",
    "df['segment']=['T&D' if x == 'transmission' or x =='distribution' or x=='T&D' else x for x in df['utility_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_dummy=pd.get_dummies(df.segment)\n",
    "debt_dummy=pd.get_dummies(df.debt_tercile)\n",
    "cash_dummy=pd.get_dummies(df.cash_tercile)\n",
    "asset_dummy=pd.get_dummies(df.asset_tercile)\n",
    "new_debt_dummy=pd.get_dummies(df.debt_median)\n",
    "new_cash_dummy=pd.get_dummies(df.cash_median)\n",
    "new_asset_dummy=pd.get_dummies(df.asset_median)\n",
    "regulation_dummy=pd.get_dummies(df.deregulation,prefix='dereg')\n",
    "retail_dummy=pd.get_dummies(df.retail_choice,prefix='ret_choice')\n",
    "year_dummy=pd.get_dummies(df.year,prefix='year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,segment_dummy,debt_dummy,cash_dummy,asset_dummy,regulation_dummy,retail_dummy,year_dummy,new_debt_dummy,new_cash_dummy,new_asset_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some more interacting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['vertical_dereg']=df['vertical']*df['dereg_YES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['post_debt']=df['post'] *df['debt_asset']\n",
    "df['post_LT_debt']=df['post'] * df['LT_debt_asset']\n",
    "df['post_four_LT_debt']=df['post'] *df['four_lags_LT_debt_asset']\n",
    "df['post_ST_debt']=df['post'] * df['ST_debt_asset']\n",
    "df['post_four_ST_debt']=df['post'] *df['four_lags_ST_debt_asset']\n",
    "df['post_four_debt']=df['post'] *df['four_lags_debt_asset']\n",
    "df['post_cash']=df['post'] *df['cash_asset']\n",
    "df['post_four_cash']=df['post'] *df['four_lags_cash_asset']\n",
    "df['post_cash_flow']=df['post'] *df['cash_flow_asset']\n",
    "df['post_retained_earn_asset']=df['post'] *df['retainedearnings_asset']\n",
    "df['post_external_finance']=df.post*df.external_finance\n",
    "df['post_highdebt']=df['post']*df['high_debt']\n",
    "df['post_meddebt']=df['post']*df['medium_debt']\n",
    "df['post_lowdebt']=df['post']*df['low_debt']\n",
    "\n",
    "\n",
    "df['post_quarter1']=df['post']*df['quarter_1']\n",
    "df['post_quarter2']=df['post']*df['quarter_2']\n",
    "df['post_quarter3']=df['post']*df['quarter_3']\n",
    "df['post_quarter4']=df['post']*df['quarter_4']\n",
    "\n",
    "\n",
    "df['post_dereg_YES']=df['post']*df.dereg_YES\n",
    "df['post_dereg_NO']=df['post']*df.dereg_NO\n",
    "df['post_dereg_suspended']=df['post']*df.dereg_SUSPENDED\n",
    "df['post_vertical']=df['post']*df['vertical']\n",
    "df['post_vertical_dereg']=df['post']* df['vertical']* df['dereg_YES']\n",
    "\n",
    "df['post_retail_YES']=df['post']*df.ret_choice_YES\n",
    "df['post_retail_NO']=df['post']*df.ret_choice_NO\n",
    "df['post_retail_suspended']=df['post']*df.ret_choice_SUSPENDED\n",
    "\n",
    "df['post_subsid']=df['post']*df['stko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['post_year_debt']=df['post'] *df['year_debt']\n",
    "df['post_year_LT_debt']=df['post'] * df['year_LT_debt']\n",
    "df['post_year_ST_debt']=df['post'] * df['year_ST_debt']\n",
    "df['post_year_cash']=df['post'] *df['year_cash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['post_sept08']=[1 if x>=datetime.datetime(2008,9,1) else 0 for x in df['date']] #lehman brothers collapse\n",
    "df['firstyear']=[1 if x>datetime.datetime(2007,6,30) and x<=datetime.datetime(2008,6,30) else 0 for x in df['date']]\n",
    "df['secondyear']=[1 if x>datetime.datetime(2008,6,30) else 0 for x in df['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['first_debt']=df['firstyear'] *df['debt_asset']\n",
    "#df['first_four_debt']=df['firstyear'] *df['four_lags_debt_asset']\n",
    "df['first_LT_debt']=df['firstyear'] * df['LT_debt_asset']\n",
    "df['first_four_LT_debt']=df['firstyear'] *df['four_lags_LT_debt_asset']\n",
    "df['first_ST_debt']=df['firstyear'] * df['ST_debt_asset']\n",
    "df['first_four_ST_debt']=df['firstyear'] *df['four_lags_ST_debt_asset']\n",
    "df['first_cash']=df['firstyear'] *df['cash_asset']\n",
    "df['first_four_cash']=df['firstyear'] *df['four_lags_cash_asset']\n",
    "df['first_cash_flow']=df['firstyear'] *df['cash_flow_asset']\n",
    "df['first_retained_earn_asset']=df['firstyear'] *df['retainedearnings_asset']\n",
    "df['first_external_finance']=df.firstyear *df.external_finance\n",
    "df['first_highdebt']=df['firstyear']*df['high_debt']\n",
    "df['first_meddebt']=df['firstyear']*df['medium_debt']\n",
    "df['first_lowdebt']=df['firstyear']*df['low_debt']\n",
    "\n",
    "df['first_quarter1']=df['firstyear']*df['quarter_1']\n",
    "df['first_quarter2']=df['firstyear']*df['quarter_2']\n",
    "df['first_quarter3']=df['firstyear']*df['quarter_3']\n",
    "df['first_quarter4']=df['firstyear']*df['quarter_4']\n",
    "\n",
    "\n",
    "df['first_dereg_YES']=df['firstyear']*df.dereg_YES\n",
    "df['first_dereg_NO']=df['firstyear']*df.dereg_NO\n",
    "df['first_dereg_suspended']=df['firstyear']*df.dereg_SUSPENDED\n",
    "df['first_vertical']=df['firstyear']*df['vertical']\n",
    "df['first_vertical_dereg']=df['firstyear']* df['vertical']* df['dereg_YES']\n",
    "\n",
    "\n",
    "df['first_retail_YES']=df['firstyear']*df.ret_choice_YES\n",
    "df['first_retail_NO']=df['firstyear']*df.ret_choice_NO\n",
    "df['first_retail_suspended']=df['firstyear']*df.ret_choice_SUSPENDED\n",
    "\n",
    "\n",
    "df['first_subsid']=df['firstyear']*df['stko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['second_debt']=df['secondyear'] *df['debt_asset']\n",
    "df['second_LT_debt']=df['secondyear'] * df['LT_debt_asset']\n",
    "df['second_four_ST_debt']=df['secondyear'] *df['four_lags_ST_debt_asset']\n",
    "df['second_ST_debt']=df['secondyear'] * df['ST_debt_asset']\n",
    "df['second_four_LT_debt']=df['secondyear'] *df['four_lags_LT_debt_asset']\n",
    "df['second_cash']=df['secondyear'] *df['cash_asset']\n",
    "df['second_four_cash']=df['secondyear'] *df['four_lags_cash_asset']\n",
    "df['second_cash_flow']=df['secondyear'] *df['cash_flow_asset']\n",
    "df['second_retained_earn_asset']=df['secondyear'] *df['retainedearnings_asset']\n",
    "df['second_external_finance']=df.secondyear *df.external_finance\n",
    "df['second_highdebt']=df['secondyear']*df['high_debt']\n",
    "df['second_meddebt']=df['secondyear']*df['medium_debt']\n",
    "df['second_lowdebt']=df['secondyear']*df['low_debt']\n",
    "\n",
    "df['second_quarter1']=df['secondyear']*df['quarter_1']\n",
    "df['second_quarter2']=df['secondyear']*df['quarter_2']\n",
    "df['second_quarter3']=df['secondyear']*df['quarter_3']\n",
    "df['second_quarter4']=df['secondyear']*df['quarter_4']\n",
    "\n",
    "\n",
    "df['second_dereg_YES']=df['secondyear']*df.dereg_YES\n",
    "df['second_dereg_NO']=df['secondyear']*df.dereg_NO\n",
    "df['second_dereg_suspended']=df['secondyear']*df.dereg_SUSPENDED\n",
    "df['second_vertical']=df['secondyear']*df['vertical']\n",
    "df['second_vertical_dereg']=df['secondyear']* df['vertical']* df['dereg_YES']\n",
    "\n",
    "df['second_retail_YES']=df['secondyear']*df.ret_choice_YES\n",
    "df['second_retail_NO']=df['secondyear']*df.ret_choice_NO\n",
    "df['second_retail_suspended']=df['secondyear']*df.ret_choice_SUSPENDED\n",
    "\n",
    "\n",
    "df['second_subsid']=df['secondyear']*df['stko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['first_year_debt']=df['firstyear'] *df['year_debt']\n",
    "df['first_year_LT_debt']=df['firstyear'] * df['year_LT_debt']\n",
    "df['first_year_ST_debt']=df['firstyear'] * df['year_ST_debt']\n",
    "df['first_year_cash']=df['firstyear'] *df['year_cash']\n",
    "\n",
    "df['second_year_debt']=df['secondyear'] *df['year_debt']\n",
    "df['second_year_LT_debt']=df['secondyear'] * df['year_LT_debt']\n",
    "df['second_year_ST_debt']=df['secondyear'] * df['year_ST_debt']\n",
    "df['second_year_cash']=df['secondyear'] *df['year_cash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for row in df['year']:\n",
    "    if row==2004:\n",
    "        dd.append(1)\n",
    "    elif row==2005:\n",
    "        dd.append(2)\n",
    "    elif row==2006:\n",
    "        dd.append(3)\n",
    "    elif row==2007:\n",
    "        dd.append(4)\n",
    "    elif row==2008:\n",
    "        dd.append(5)\n",
    "    elif row==2009:\n",
    "        dd.append(6)\n",
    "    elif row==2010:\n",
    "        dd.append(7)\n",
    "    elif row==2011:\n",
    "        dd.append(8)\n",
    "    else:\n",
    "        dd.append(0)\n",
    "df['year_time']=dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firms that have data in both pre and post crisis preiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post_crisis_firms=(df[df.date==datetime.datetime(2009,3,31)]['tic'].unique())\n",
    "pre_crisis_firms=(df[df.post==0]['tic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasting_firms=list(set(post_crisis_firms) & set(pre_crisis_firms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(lasting_firms)\n",
    "print len(post_crisis_firms)\n",
    "print len(pre_crisis_firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for tic in df['tic']:\n",
    "    if tic in lasting_firms:\n",
    "        dd.append(1)\n",
    "    else:\n",
    "        dd.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['lasting_firms']=dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF=df[df.remove==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(DF.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF=DF[DF.segment != 'generation'] # remove firms that are only involved in generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(DF.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF=DF[(DF.conm !='NIAGARA MOHAWK POWER CORP') & (DF.conm !='MAINE & MARITIMES CORP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(DF.conm.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF['stock_purchase_asset']=(DF['stock_purchase']/DF.atq) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF['sale_change']=DF['sale_asset']-DF['four_lags_sale_asset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final sample (from 2004 to 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for index,row in DF.iterrows():\n",
    "    if row['fyearq']==2004 and row['fqtr']==1:\n",
    "        dd.append(1)\n",
    "    else:\n",
    "        dd.append(0)\n",
    "DF['Q12004']=dd        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF=DF[DF['Q12004']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(DF.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF['NWC_asset']=(DF['wcapq']/DF['atq'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Operating cash flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF['OCF']=DF['oibdpq']+DF['dpq']-DF['txpq']+DF['wcapq'] #operating income, depreciation, total income tax, working cap changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF['OCF_asset']=(DF['OCF']/DF['atq']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lagged Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped=DF.groupby(['tic',])\n",
    "new=[] ## for every tic and fiscal year, \n",
    "for group in grouped.groups.keys():\n",
    "    DFF=grouped.get_group(group)\n",
    "    DFF['lag_property_sale_asset']=DFF['property_sale_asset'].shift(1)\n",
    "    DFF['lag_plant_add_asset']=DFF['plant_add_asset'].shift(1) #Utility Plant - Gross Additions\n",
    "    DFF['lag_stock_sale_asset']=DFF['stock_sale_asset'].shift(1)\n",
    "    DFF['lag_stock_purchase_asset']=DFF['stock_purchase_asset'].shift(1)\n",
    "    DFF['lag_investment_sale_asset']=DFF['investment_sale_asset'].shift(1)\n",
    "    DFF['lag_other_cash_asset']=DFF['other_cash_asset'].shift(1)\n",
    "    DFF['lag_payout_asset']=DFF['payout_asset'].shift(1)\n",
    "    DFF['lag_LT_debt_issuance_asset']=DFF['LT_debt_issuance_asset'].shift(1)\n",
    "    DFF['lag_LT_debt_reduction_asset']=DFF['LT_debt_reduction_asset'].shift(1)\n",
    "    DFF['lag_NOCF_asset']=DFF['NOCF_asset'].shift(1)\n",
    "    #DF['net_debt_issuance']=DF['total_debt_q']-DF['total_debt_q'].shift(1)\n",
    "    new.append(DFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF=pd.concat(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create RTO variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "for row in DF['state']:\n",
    "    if row=='CA':\n",
    "        dd.append('CAISO')\n",
    "    elif row=='PA' or row=='DE' or row=='IL' or row=='IN' or row=='KY' or row=='MD' or row=='MI' or row=='NJ' or row=='NC' or row=='OH' or row=='TN' or row=='VA' or row=='WV' or row=='DC':\n",
    "        dd.append('PJM')\n",
    "    elif row=='TX':\n",
    "        dd.append('ERCOT')\n",
    "    else:\n",
    "        dd.append(None)\n",
    "DF['RTO']=dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RRA ratings variable that reflects opinion on Public Utility Commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "start_time=time()\n",
    "dd=[]\n",
    "for index,row in DF.iterrows():\n",
    "    if row['state']=='AL':\n",
    "        dd.append(2)\n",
    "    elif row['state']=='AZ' and row['date']>=datetime.datetime(2005,3,1):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='AZ' and row['date']<datetime.datetime(2005,3,1):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='AR' and row['date']>=datetime.datetime(2006,4,7):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='AR' and row['date']<datetime.datetime(2006,4,7):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='CA' and row['date']>=datetime.datetime(2007,4,5):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='CA' and row['date']>=datetime.datetime(2005,12,29) and row['date']<datetime.datetime(2007,4,5):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='CA' and row['date']>=datetime.datetime(2004,4,15) and row['date']<datetime.datetime(2005,12,29):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='CA' and row['date']<datetime.datetime(2004,4,15):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='CO' and row['date']>=datetime.datetime(2007,8,21):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='CO' and row['date']<datetime.datetime(2007,8,21):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='CT' and row['date']<datetime.datetime(2008,4,1):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='CT' and row['date']>=datetime.datetime(2008,4,1) and row['date']<datetime.datetime(2009,3,23):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='CT' and row['date']>=datetime.datetime(2009,3,23) and row['date']<datetime.datetime(2009,7,16):\n",
    "        dd.append(8)\n",
    "    elif row['state']=='CT' and row['date']>=datetime.datetime(2009,7,16):\n",
    "        dd.append(9)\n",
    "    elif row['state']=='DC':\n",
    "        dd.append(5)\n",
    "    elif row['state']=='DE':\n",
    "        dd.append(4)\n",
    "    elif row['state']=='HI':\n",
    "        dd.append(5)\n",
    "    elif row['state']=='FL' and row['date']>=datetime.datetime(2010,1,13):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='FL' and row['date']>=datetime.datetime(2009,10,2) and row['date']<datetime.datetime(2010,1,13):\n",
    "        dd.append(3)\n",
    "    elif row['state']=='FL' and row['date']<datetime.datetime(2009,10,2):\n",
    "        dd.append(2)\n",
    "    elif row['state']=='GA' and row['date']>=datetime.datetime(2005,10,5):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='GA' and row['date']<datetime.datetime(2005,10,5):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='ID' and row['date']>=datetime.datetime(2010,8,27):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='ID' and row['date']<datetime.datetime(2010,8,27):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='IL' and row['date']>=datetime.datetime(2007,4,5):\n",
    "        dd.append(8)\n",
    "    elif row['state']=='IL' and row['date']>=datetime.datetime(2005,9,23) and row['date']<datetime.datetime(2007,4,5):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='IL' and row['date']<datetime.datetime(2005,9,23):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='IN' and row['date']>=datetime.datetime(2009,7,15):\n",
    "        dd.append(3)\n",
    "    elif row['state']=='IN' and row['date']<datetime.datetime(2009,7,15):\n",
    "        dd.append(2)\n",
    "    elif row['state']=='IA' and row['date']>=datetime.datetime(2007,2,1):\n",
    "        dd.append(3)\n",
    "    elif row['state']=='IA' and row['date']<datetime.datetime(2007,2,1):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='KS' and row['date']>=datetime.datetime(2008,3,27):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='KS' and row['date']<datetime.datetime(2008,3,27):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='KY' and row['date']>=datetime.datetime(2010,12,9):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='KY' and row['date']>=datetime.datetime(2005,4,1) and row['date']<datetime.datetime(2010,12,9):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='KY' and row['date']<datetime.datetime(2005,4,1):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='LA' and row['date']>=datetime.datetime(2007,10,16):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='LA' and row['date']<datetime.datetime(2007,10,16):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='MD' and row['date']<datetime.datetime(2006,4,11):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='MD' and row['date']>=datetime.datetime(2006,4,11) and row['date']<datetime.datetime(2008,1,18):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='MD' and row['date']>=datetime.datetime(2008,1,18) and row['date']<datetime.datetime(2008,5,12):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='MD' and row['date']>=datetime.datetime(2008,5,12) and row['date']<datetime.datetime(2009,7,15):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='MD' and row['date']>=datetime.datetime(2009,7,15):\n",
    "        dd.append(8)\n",
    "    elif row['state']=='MA':\n",
    "        dd.append(4)\n",
    "    elif row['state']=='MI' and row['date']<datetime.datetime(2004,4,12):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='MI' and row['date']>=datetime.datetime(2004,4,12) and row['date']<datetime.datetime(2010,4,9):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='MI' and row['date']>=datetime.datetime(2010,4,9):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='MS' and row['date']<datetime.datetime(2008,7,15):\n",
    "        dd.append(3)\n",
    "    elif row['state']=='MS' and row['date']>=datetime.datetime(2008,7,15):\n",
    "        dd.append(2)\n",
    "    elif row['state']=='MN':\n",
    "        dd.append(5)\n",
    "    elif row['state']=='MO' and row['date']<datetime.datetime(2008,1,8):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='MO' and row['date']>=datetime.datetime(2008,1,8):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='MT':\n",
    "        dd.append(7)\n",
    "    elif row['state']=='NE' and row['date']<datetime.datetime(2004,1,28):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='NE' and row['date']>=datetime.datetime(2008,1,28):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='NV' and row['date']<datetime.datetime(2006,11,1):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='NV' and row['date']>=datetime.datetime(2006,11,1) and row['date']<datetime.datetime(2007,5,23):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='NV' and row['date']>=datetime.datetime(2007,5,23):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='NH':\n",
    "        dd.append(6)\n",
    "    elif row['state']=='NM' and row['date']<datetime.datetime(2004,1,5):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='NM' and row['date']>=datetime.datetime(2004,1,5) and row['date']<datetime.datetime(2008,4,1):\n",
    "        dd.append(6)  \n",
    "    elif row['state']=='NM' and row['date']>=datetime.datetime(2008,4,1):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='NY' and row['date']>=datetime.datetime(2007,10,24):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='NY' and row['date']<datetime.datetime(2007,10,24):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='OH' and row['date']<datetime.datetime(2009,10,8):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='OH' and row['date']>=datetime.datetime(2009,10,8):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='OK' and row['date']<datetime.datetime(2007,10,15):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='OK' and row['date']>=datetime.datetime(2007,10,15):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='OR' and row['date']<datetime.datetime(2004,2,1):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='OR' and row['date']>=datetime.datetime(2004,2,1) and row['date']<datetime.datetime(2006,1,6):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='OR' and row['date']>=datetime.datetime(2006,1,6) and row['date']<datetime.datetime(2006,9,22):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='OR' and row['date']>=datetime.datetime(2006,9,22):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='PA':\n",
    "        dd.append(6)\n",
    "    elif row['state']=='SC':\n",
    "        dd.append(4)\n",
    "    elif row['state']=='SD':\n",
    "        dd.append(5)\n",
    "    elif row['state']=='TN':\n",
    "        dd.append(4)\n",
    "    elif row['state']=='TX':\n",
    "        dd.append(7)\n",
    "    elif row['state']=='WI':\n",
    "        dd.append(2)\n",
    "    elif row['state']=='WV'and row['date']>=datetime.datetime(2008,3,28):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='WV'and row['date']<datetime.datetime(2008,3,28):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='NJ'and row['date']>=datetime.datetime(2004,5,12):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='NJ'and row['date']<datetime.datetime(2004,5,12):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='NC':\n",
    "        dd.append(5)\n",
    "    elif row['state']=='VA':\n",
    "        dd.append(3)\n",
    "    elif row['state']=='VT' and row['date']<datetime.datetime(2005,4,27):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='VT' and row['date']>=datetime.datetime(2005,4,27) and row['date']<datetime.datetime(2007,4,1):\n",
    "        dd.append(7)\n",
    "    elif row['state']=='VT' and row['date']>=datetime.datetime(2007,4,1):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='WA' and row['date']<datetime.datetime(2008,1,8):\n",
    "        dd.append(4)\n",
    "    elif row['state']=='WA' and row['date']>=datetime.datetime(2008,1,8) and row['date']<datetime.datetime(2010,4,9):\n",
    "        dd.append(5)\n",
    "    elif row['state']=='WA' and row['date']>=datetime.datetime(2010,4,9):\n",
    "        dd.append(6)\n",
    "    elif row['state']=='WI':\n",
    "        dd.append(2)\n",
    "    else:\n",
    "        dd.append(None)\n",
    "end_time=time()\n",
    " \n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF['RRA']=dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF['stock_payout']=DF['stock_sale_asset']*DF['payout_asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF.to_csv('.../data/sample')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
